# 因子数据库构建流程

## 总体架构

```mermaid
graph TB
    A[因子配置文件] --> B[因子工厂]
    C[市场数据] --> B
    D[股票池] --> B
    B --> E[因子数据库]
    E --> F[质量报告]
    
    subgraph "配置层"
        A
    end
    
    subgraph "数据层"
        C
        D
    end
    
    subgraph "处理层"
        B
    end
    
    subgraph "输出层"
        E
        F
    end
```

## 文件结构

```
alpha_local/
├── factor_config.py           # 因子配置文件
├── factor_database_builder.py # 因子数据库构建器类
├── feval_factor_database.py   # 执行文件(因子工厂)
├── factor_processing_utils.py  # 因子处理工具函数
└── factor_lib/                # 数据存储目录
    ├── raw/                   # 原始因子数据
    ├── processed/             # 预处理后因子数据
    └── final/                 # 最终因子数据库
```

## 核心流程

### 1. 配置加载阶段
```mermaid
graph LR
    A[factor_config.py] --> B[FACTOR_DICT]
    A --> C[DEFAULT_CONFIG]
    B --> D[因子表达式]
    C --> E[基础参数]
```

**输入**：
- 因子定义字典 `FACTOR_DICT`
- 基础配置 `DEFAULT_CONFIG`

**输出**：
- 因子表达式列表
- 时间范围、股票池等参数

### 2. 数据准备阶段
```mermaid
graph TB
    A[INDEX_FIX] --> B[动态券池]
    C[get_price] --> D[市场数据]
    
    subgraph "市场数据字段"
        D1[开盘价 open]
        D2[收盘价 close]
        D3[最高价 high]
        D4[最低价 low]
        D5[涨停价 limit_up]
        D6[跌停价 limit_down]
        D7[成交额 total_turnover]
        D8[成交量 volume]
    end
    
    D --> D1
    D --> D2
    D --> D3
    D --> D4
    D --> D5
    D --> D6
    D --> D7
    D --> D8
```

**输入**：
- 时间范围：`start_date` → `end_date`
- 指数代码：`index_item`

**输出**：
- 股票池：`stock_universe` (日期 × 股票)
- 市场数据：`market_data` (MultiIndex格式)

### 3. 因子构建阶段
```mermaid
graph TB
    A[FactorDatabaseBuilder] --> B[逐个构建因子]
    
    B --> C{检查缓存}
    C -->|存在| D[加载缓存]
    C -->|不存在| E[重新计算]
    
    E --> F[execute_factor]
    F --> G[原始因子数据]
    G --> H[preprocess_factor]
    
    subgraph "因子预处理流程"
        H1[新股过滤]
        H2[ST股过滤]
        H3[停牌过滤]
        H4[离群值处理MAD]
        H5[标准化处理]
        H6[中性化处理]
        H7[涨停过滤]
    end
    
    H --> H1
    H1 --> H2
    H2 --> H3
    H3 --> H4
    H4 --> H5
    H5 --> H6
    H6 --> H7
    
    H7 --> I[处理后因子]
    D --> I
    I --> J[stack转长格式]
    J --> K[保存到processed/]
```

**核心步骤**：
1. **缓存检查**：避免重复计算
2. **原始计算**：`execute_factor()` 执行因子表达式
3. **数据清洗**：`preprocess_factor()` 多重过滤和处理
4. **格式转换**：宽表 → 长表 (MultiIndex)
5. **缓存保存**：存储到 `processed/` 目录

### 4. 数据合并阶段
```mermaid
graph TB
    A[所有因子数据] --> B[pd.concat 批量拼接]
    C[市场数据] --> D[pd.concat 与价格合并]
    B --> D
    
    subgraph "拼接策略"
        D1[inner: 只保留共同数据]
        D2[left: 以价格数据为准]
        D3[outer: 保留所有数据]
    end
    
    D --> D1
    D --> D2
    D --> D3
    
    D1 --> E[最终因子数据库]
    D2 --> E
    D3 --> E
```

**输入**：
- 多个因子的长格式数据
- 市场数据 (价格、成交量等)

**输出**：
- 统一的因子数据库 DataFrame
- 索引：(股票代码, 日期)
- 列：价格字段 + 因子字段

### 5. 质量检查阶段
```mermaid
graph TB
    A[最终数据库] --> B[质量检查]
    
    subgraph "质量指标"
        B1[数据完整性]
        B2[缺失率统计]
        B3[唯一值检查]
        B4[分布特征]
        B5[离群值比例]
    end
    
    B --> B1
    B --> B2
    B --> B3
    B --> B4
    B --> B5
    
    B1 --> C[质量评分]
    B2 --> C
    B3 --> C
    B4 --> C
    B5 --> C
    
    C --> D[质量报告]
```

**质量评估标准**：
- 缺失率 < 20%：满分
- 缺失率 20-50%：扣15分
- 缺失率 > 50%：扣30分
- 离群值 > 10%：扣20分
- 唯一值 < 10%：扣15分

### 6. 结果保存阶段
```mermaid
graph TB
    A[最终数据库] --> B[保存到final/]
    C[质量报告] --> D[控制台输出]
    
    subgraph "存储格式"
        B1[factor_db_指数_开始日期_结束日期.pkl]
    end
    
    B --> B1
    
    subgraph "输出信息"
        D1[数据形状]
        D2[列名列表]
        D3[质量摘要]
    end
    
    D --> D1
    D --> D2
    D --> D3
```

## 缓存机制

```mermaid
graph TB
    A[因子计算请求] --> B{检查processed缓存}
    B -->|存在| C[直接加载]
    B -->|不存在| D{检查raw缓存}
    D -->|存在| E[加载原始数据]
    D -->|不存在| F[重新计算]
    
    F --> G[execute_factor]
    G --> H[保存到raw/]
    H --> I[preprocess_factor]
    E --> I
    I --> J[保存到processed/]
    J --> C
    
    C --> K[返回因子数据]
```

**缓存层级**：
1. **Level 1**: `processed/` - 完全处理好的因子
2. **Level 2**: `raw/` - 原始计算结果
3. **Level 3**: `final/` - 最终数据库

## 数据流转

```mermaid
graph LR
    A[原始财务数据] --> B[因子表达式]
    B --> C[原始因子值]
    C --> D[数据清洗]
    D --> E[标准化因子]
    E --> F[长格式转换]
    F --> G[批量合并]
    G --> H[与价格数据拼接]
    H --> I[最终因子数据库]
    
    subgraph "数据格式变化"
        J[宽表: 日期×股票]
        K[长表: MultiIndex]
        L[合并表: 价格+因子]
    end
    
    C --> J
    F --> K
    I --> L
```

## 配置参数

### 核心配置
```python
DEFAULT_CONFIG = {
    "start_date": "2015-01-01",     # 开始日期
    "end_date": "2025-07-01",       # 结束日期  
    "index_item": "000852.XSHG",    # 指数代码(中证1000)
    "join_type": "inner",           # 合并方式
    "force_rebuild": False,         # 是否强制重建
    "cache_dir": "factor_lib"       # 缓存目录
}
```

### 因子定义
```python
FACTOR_DICT = {
    "cfoa_mrq": 经营性现金流/总资产,      # 现金流资产比
    "atdy_mrq": 资产周转率同比变化,        # 运营效率
    "ccr_mrq": 经营性现金流/流动负债,      # 偿债能力
}
```

## 使用方式

### 快速开始
```python
# 1. 运行因子工厂
python feval_factor_database.py

# 2. 或者在代码中调用
from feval_factor_database import factor_factory
df, report = factor_factory()
```

### 自定义使用
```python
from factor_database_builder import FactorDatabaseBuilder
from factor_config import FACTOR_DICT, DEFAULT_CONFIG

# 创建构建器
builder = FactorDatabaseBuilder()

# 自定义参数
df, report = builder.build_factor_database(
    factor_dict=FACTOR_DICT,
    # ... 其他参数
    force_rebuild=True  # 强制重建
)
```

## 扩展指南

### 添加新因子
1. 在 `factor_config.py` 中添加因子定义
2. 重新运行 `feval_factor_database.py`
3. 系统自动处理新因子

### 修改处理逻辑
1. 编辑 `factor_processing_utils.py` 中的处理函数
2. 设置 `force_rebuild=True` 重新处理

### 性能优化
1. **并行计算**：多进程处理多个因子
2. **增量更新**：只计算新增时间段
3. **内存优化**：使用 float32 减少内存使用

## 输出示例

```
准备动态券池
获取市场数据  
加载因子配置文件
加载了 3 个因子: ['cfoa_mrq', 'atdy_mrq', 'ccr_mrq']

开始构建因子数据库，共 3 个因子
时间范围: 2015-01-01 到 2025-07-01
股票数量: 2686

[1/3] 处理因子: cfoa_mrq
加载缓存因子: cfoa_mrq

[2/3] 处理因子: atdy_mrq  
加载缓存因子: atdy_mrq

[3/3] 处理因子: ccr_mrq
加载缓存因子: ccr_mrq

拼接 3 个因子...
合并价格数据，使用 inner 连接...
生成质量报告...
质量摘要: 平均分 100.0, 优良因子 3/3
保存最终数据库...
构建完成！
   最终数据: 2397832 行 × 11 列
   文件大小: 245.8 MB
   保存路径: factor_lib/final/factor_db_000852.XSHG_2015-01-01_2025-07-01.pkl

最终结果:
数据形状: (2397832, 11)
列名: ['open', 'close', 'high', 'low', 'limit_up', 'limit_down', 
       'total_turnover', 'volume', 'cfoa_mrq', 'atdy_mrq', 'ccr_mrq']
```

---

*这套因子数据库构建系统具有高度的模块化、可扩展性和容错性，支持大规模因子的批量处理和管理。*
